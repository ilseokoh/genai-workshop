{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Text Classification with Generative Models on Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/text_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/text_classification.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/text_classification.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "PaLM 2와 같은 생성 모델은 다양한 자연어 처리(NLP) 작업에 사용되는 강력한 언어 모델입니다. 그 중 하나가 텍스트 분류입니다. 이는 주어진 텍스트에 하나 이상의 범주를 할당하는 작업을 포함합니다. 전통적인 NLP 기술을 사용하여 텍스트 분류를 수행할 수 있지만 LLM은 프롬프트(도메인별 레이블이 지정된 데이터와 반대)를 제공하여 분류를 수행할 수 있으므로 텍스트 분류 솔루션을 구축하는 데 걸리는 시간을 단축할 수 있습니다. LLM 기반 분류 모델은 사용자 정의 모델 교육을 통해 많은 예제를 통해 추가로 조정할 수 있지만 이는 이 노트북의 범위를 벗어납니다.\n",
    "\n",
    "이 노트북에서는 PaLM API의 프롬프트를 사용하여 텍스트 분류를 수행하는 방법을 살펴보겠습니다. [공식 문서](https://cloud.google.com/vertex-ai/docs/generative-ai/text/classification-prompts)에서 분류 프롬프트에 대해 자세히 알아보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 목적\n",
    "\n",
    "노트북이 끝나면 대규모 언어 모델을 사용하여 다음을 포함한 다양한 분류 작업을 수행할 수 있게 됩니다.\n",
    "\n",
    "* 제로샷 프롬프트 텍스트 분류\n",
    "* 퓨샷 프롬프트 텍스트 분류\n",
    "* 일반적인 작업:\n",
    "     * 감성 분석\n",
    "     * 주제 분류\n",
    "     * 스팸 감지\n",
    "     * 의도 인식\n",
    "     * 언어 식별\n",
    "     * 독성 감지\n",
    "     * 감정 감지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSyXtwyz_o_v"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9977,
     "status": "ok",
     "timestamp": 1699927666574,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "82ad0c445061",
    "outputId": "2a2e89af-d5eb-4694-9a05-2a7383c82b0d"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0JYIfR_kmjY"
   },
   "source": [
    "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLT0_4I7kmjY"
   },
   "source": [
    "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-N1cvbxckmjY"
   },
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8570,
     "status": "ok",
     "timestamp": 1699927684046,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1699927686939,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPcn5dZ7O-b"
   },
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2eDjxvafo5W"
   },
   "source": [
    "In the section below, you will explore zero-shot prompting, few-shot prompting, and some common types of text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC3qkPZ8jFkY"
   },
   "source": [
    "### Zero-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8RFu2ZX_o_y"
   },
   "source": [
    "Zero-shot prompting is where you do not provide examples with labels, and rely on the LLM to make the classification on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1699927738334,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "_uNNGhC_e1nZ",
    "outputId": "ed40b75e-a902-489b-f682-e387cd5cee91"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "다음을 분류하십시오.\\n\n",
    "텍스트: \"오늘 공원에서 꼬리가 길고 눈이 큰 털복숭이 동물을 봤어요.\"\n",
    "라벨: 개, 고양이\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjl-tckTjK2B"
   },
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UC0w7n5_o_z"
   },
   "source": [
    "With few-shot prompting, you provide examples to the PaLM model and expect it to predict classes based on the provided examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1699927851838,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "b8jYL-hBjMtW",
    "outputId": "7934a23a-4395-47b6-e4f1-128307c4bf44"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "특정 뉴스 헤드라인의 주제는 무엇입니까?\n",
    "- 비즈니스\n",
    "- 엔터테인먼트\n",
    "- 건강\n",
    "- 스포츠\n",
    "- 기술\n",
    "\n",
    "텍스트: Pixel 7 Pro 전문가 직접 검토.\n",
    "답: 기술\n",
    "\n",
    "문자: 담배를 끊으시겠어요?\n",
    "답: 건강\n",
    "\n",
    "텍스트: 버디인가, 보기인가? 언더파를 기록하기 위한 5가지 팁\n",
    "답: 스포츠\n",
    "\n",
    "텍스트: 지역 최저 임금 인상 완화로 인해 더 멀어질 전망\n",
    "답: 비즈니스\n",
    "\n",
    "텍스트: 영화 시사회를 위해 이탈리아 바리에 방금 도착한 사람이 누구인지 짐작할 수 없습니다.\n",
    "답:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaiMLs4SjNLi"
   },
   "source": [
    "### Other classification examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhkcRWrh_o_0"
   },
   "source": [
    "아래에서 제로샷 프롬프트를 기반으로 하는 좀 더 일반적인 텍스트 분류 프롬프트를 살펴보세요. 또한 사용자 정의 텍스트 예제와 관련 출력 클래스를 제공하여 이들 중 일부를 몇 번의 프롬프트로 전환할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tEjKEAtXjf8"
   },
   "source": [
    "#### Topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1699927925825,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "bCnuQRVSXmyr",
    "outputId": "8837eb68-7a69-4198-d7a6-839bcb2b7065"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "스포츠, 정치, 엔터테인먼트 등 미리 정의된 여러 주제 중 하나로 텍스트를 분류합니다.\n",
    "\n",
    "텍스트: 바이든 대통령은 몇 가지 기회를 논의하기 위해 3월에 인도를 방문할 예정입니다.\n",
    "분류:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB6rZD-6YAkC"
   },
   "source": [
    "####  Spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1699927985845,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "OfyHvhBfX_P_",
    "outputId": "3082882b-c0f5-4a19-bc7d-ec73fe7846d5"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "이메일이 주어지면 스팸인지 스팸이 아닌지 분류하세요.\n",
    "\n",
    "이메일: 안녕하세요, 사용자님,\n",
    "       귀하는 복권 당첨자로 선정되었으며 최대 100만 달러까지 당첨될 수 있습니다.\n",
    "       귀하의 은행 정보를 친절하게 공유해 주시면 거기서부터 진행할 수 있습니다.\n",
    "\n",
    "       미국 공식 복권 부서\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHKcxx0TYrGv"
   },
   "source": [
    "#### Intent recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1699928015948,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "DsseGvWNYvK3",
    "outputId": "dcaf489f-3e01-472e-ab8f-15ef49d3102a"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "사용자의 입력을 바탕으로 '정보 찾기', '예약하기', '주문하기' 등 의도를 분류합니다.\n",
    "사용자 입력: 안녕하세요. 5월 1일 Juan에 2인용 테이블을 예약해 주실 수 있나요?\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stsfav5aZtqV"
   },
   "source": [
    "#### Language identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1699928041042,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "88TqQSXIZxts",
    "outputId": "be2420c5-723b-442d-9e5c-f7da64116339"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "텍스트가 주어지면 해당 텍스트가 작성된 언어를 분류하십시오. \\n\n",
    "텍스트: Selam nasıl gidiyor?\n",
    "언어:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z_jmrhOZ15J"
   },
   "source": [
    "#### Toxicity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1699928088328,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "Umloy-o1Z5us",
    "outputId": "6dab284f-4c61-4c33-f114-18ddb496da80"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "텍스트가 주어지면 긍정 또는 부정으로 분류하세요.\n",
    "텍스트: 난 화창한 날을 좋아해\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTH5MeiVZ6Hr"
   },
   "source": [
    "#### Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1699928109954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "u5ETwBSrZ-Xn",
    "outputId": "700e4f4e-13ff-4148-c6c9-9846e4f4ad6b"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "텍스트가 주어지면 그것이 전달하는 감정(예: 행복, 분노)을 분류하세요.\n",
    "문자: 어제 뉴스가 아직도 너무 기뻐요\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=256,\n",
    "        temperature=0.1,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ddaadac64c7"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5e2266cb257"
   },
   "source": [
    "텍스트 분류 작업의 출력을 평가할 수 있습니다. 어떻게 작동하는지 보여주기 위해 제품 리뷰와 실제 감정이 포함된 간단한 데이터 프레임을 만드는 것부터 시작하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1699928226788,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "b0e04a03f24f",
    "outputId": "13fa798c-d337-48c0-d6e0-9ca376c0606c"
   },
   "outputs": [],
   "source": [
    "review_data = {\n",
    "    \"review\": [\n",
    "        \"나는 이 제품을 좋아합니다. 내가 찾고 있는 모든 것을 갖추고 있습니다!\",\n",
    "         \"제가 드릴 수 있는 말은 이 제품을 구매하신 후 당신이 행복해질 것이라는 것뿐입니다.\",\n",
    "         \"너무 비싸고 가격 대비 가치가 없습니다\",\n",
    "         \"기분은 괜찮아요. 좋지도 나쁘지도 않아요.\"\n",
    "    ],\n",
    "    \"sentiment_groundtruth\": [\"긍정\", \"긍정\", \"부정\", \"중립\"],\n",
    "}\n",
    "\n",
    "review_data_df = pd.DataFrame(review_data)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "088327f41a26"
   },
   "source": [
    "이제 리뷰와 감정이 실측 라벨로 포함된 데이터가 있으므로 '적용' 기능을 사용하여 각 리뷰 행에 텍스트 생성 모델을 호출할 수 있습니다. 각 행은 'review' 열의 프롬프트를 사용하여 PaLM API를 사용하여 감정을 예측하고 결과를 'sentiment_prediction' 열에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 2511,
     "status": "ok",
     "timestamp": 1699928322008,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "0fb691b6c721",
    "outputId": "bb235697-019d-4cde-9bc2-bd83496a4a65"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(row):\n",
    "    prompt = f\"\"\"다음 리뷰의 감정을 \"긍정\", \"중립\", \"부정\"으로 분류합니다.\n",
    "                리뷰: {row} \\n\n",
    "                감정:\n",
    "              \"\"\"\n",
    "    response = generation_model.predict(prompt=prompt).text\n",
    "    return response\n",
    "\n",
    "\n",
    "review_data_df[\"sentiment_prediction\"] = review_data_df[\"review\"].apply(get_sentiment)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "908c72bdf4c7"
   },
   "source": [
    "결국 sklearn에서 'classification_report' 함수를 호출하여 실제 감정 'sentiment_groundtruth' 및 예측된 감정 'sentiment_prediction'을 전달하여 정확도 및 기타 분류 측정항목을 측정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1035,
     "status": "ok",
     "timestamp": 1699928365975,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -540
    },
    "id": "7f22690ae395",
    "outputId": "398be831-a132-4bca-f50a-901c49f61d53"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        review_data_df[\"sentiment_groundtruth\"], review_data_df[\"sentiment_prediction\"]\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
